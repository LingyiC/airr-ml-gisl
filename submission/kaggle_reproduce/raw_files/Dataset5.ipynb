{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "abdf45f9",
   "metadata": {},
   "source": [
    "# Combining Multiple K-mer Sizes for Baseline Model\n",
    "\n",
    "This notebook combines 3-mer and 4-mer encoding with L1-regularized logistic regression.\n",
    "\n",
    "**Why combine k-mers?**\n",
    "- Different biological signals live at different motif lengths\n",
    "- 3-mers capture general motifs, 4-mers capture more specific ones\n",
    "- With L1 regularization, the model can pick whichever k-mers are actually useful\n",
    "\n",
    "**Memory Considerations:**\n",
    "- Memory constraint: 24GB available\n",
    "- Batch processing implemented for both encoding and scoring\n",
    "- Sparse k-mer representations to reduce memory footprint\n",
    "- Only keep k-mers that appear in training data to avoid explosion of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b04e5de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.12.12 | packaged by Anaconda, Inc. | (main, Oct 21 2025, 20:16:04) [GCC 11.2.0]\n",
      "Available RAM: 31.3 GB\n"
     ]
    }
   ],
   "source": [
    "## imports used by the basic code template provided.\n",
    "\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import glob\n",
    "import sys\n",
    "import argparse\n",
    "from collections import defaultdict, Counter\n",
    "from typing import Iterator, Tuple, Union, List\n",
    "import psutil\n",
    "import gc\n",
    "import pickle\n",
    "\n",
    "## imports that are additionally used by this notebook\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score, train_test_split\n",
    "from sklearn.metrics import roc_auc_score, balanced_accuracy_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "print(f\"Python version: {sys.version}\")\n",
    "print(f\"Available RAM: {psutil.virtual_memory().total / (1024**3):.1f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c22f400",
   "metadata": {},
   "source": [
    "## Memory Monitoring Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e1e664b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory] Initial - Process: 0.52GB, Available: 15.42GB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.5184707641601562, 15.423412322998047)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LC: Had local memory issue. So added this. \n",
    "class MemoryMonitor:\n",
    "    \"\"\"Monitor memory usage throughout the pipeline.\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_memory_usage():\n",
    "        \"\"\"Get current memory usage in GB.\"\"\"\n",
    "        process = psutil.Process(os.getpid())\n",
    "        return process.memory_info().rss / (1024**3)\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_available_memory():\n",
    "        \"\"\"Get available system memory in GB.\"\"\"\n",
    "        return psutil.virtual_memory().available / (1024**3)\n",
    "    \n",
    "    @staticmethod\n",
    "    def log_memory(label=\"\"):\n",
    "        \"\"\"Log current memory usage.\"\"\"\n",
    "        used = MemoryMonitor.get_memory_usage()\n",
    "        available = MemoryMonitor.get_available_memory()\n",
    "        print(f\"[Memory] {label} - Process: {used:.2f}GB, Available: {available:.2f}GB\")\n",
    "        return used, available\n",
    "\n",
    "MemoryMonitor.log_memory(\"Initial\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29dd978b",
   "metadata": {},
   "source": [
    "## Utility Functions for Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec547a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same as basline code template provided\n",
    "def load_data_generator(data_dir: str, metadata_filename='metadata.csv') -> Iterator[\n",
    "    Union[Tuple[str, pd.DataFrame, bool], Tuple[str, pd.DataFrame]]]:\n",
    "    \"\"\"\n",
    "    A generator to load immune repertoire data.\n",
    "\n",
    "    This function operates in two modes:\n",
    "    1.  If metadata is found, it yields data based on the metadata file.\n",
    "    2.  If metadata is NOT found, it uses glob to find and yield all '.tsv'\n",
    "        files in the directory.\n",
    "\n",
    "    Args:\n",
    "        data_dir (str): The path to the directory containing the data.\n",
    "\n",
    "    Yields:\n",
    "        An iterator of tuples. The format depends on the mode:\n",
    "        - With metadata: (repertoire_id, pd.DataFrame, label_positive)\n",
    "        - Without metadata: (filename, pd.DataFrame)\n",
    "    \"\"\"\n",
    "    metadata_path = os.path.join(data_dir, metadata_filename)\n",
    "\n",
    "    if os.path.exists(metadata_path):\n",
    "        metadata_df = pd.read_csv(metadata_path)\n",
    "        for row in metadata_df.itertuples(index=False):\n",
    "            file_path = os.path.join(data_dir, row.filename)\n",
    "            try:\n",
    "                repertoire_df = pd.read_csv(file_path, sep='\\t')\n",
    "                yield row.repertoire_id, repertoire_df, row.label_positive\n",
    "            except FileNotFoundError:\n",
    "                print(f\"Warning: File '{row.filename}' listed in metadata not found. Skipping.\")\n",
    "                continue\n",
    "    else:\n",
    "        search_pattern = os.path.join(data_dir, '*.tsv')\n",
    "        tsv_files = glob.glob(search_pattern)\n",
    "        for file_path in sorted(tsv_files):\n",
    "            try:\n",
    "                filename = os.path.basename(file_path)\n",
    "                repertoire_df = pd.read_csv(file_path, sep='\\t')\n",
    "                yield filename, repertoire_df\n",
    "            except Exception as e:\n",
    "                print(f\"Warning: Could not read file '{file_path}'. Error: {e}. Skipping.\")\n",
    "                continue\n",
    "\n",
    "# Same as basline code template provided\n",
    "def load_full_dataset(data_dir: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Loads all TSV files from a directory and concatenates them into a single DataFrame.\n",
    "\n",
    "    This function handles two scenarios:\n",
    "    1. If metadata.csv exists, it loads data based on the metadata and adds\n",
    "       'repertoire_id' and 'label_positive' columns.\n",
    "    2. If metadata.csv does not exist, it loads all .tsv files and adds\n",
    "       a 'filename' column as an identifier.\n",
    "\n",
    "    Args:\n",
    "        data_dir (str): The path to the data directory.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A single, concatenated DataFrame containing all the data.\n",
    "    \"\"\"\n",
    "    metadata_path = os.path.join(data_dir, 'metadata.csv')\n",
    "    df_list = []\n",
    "    data_loader = load_data_generator(data_dir=data_dir)\n",
    "\n",
    "    if os.path.exists(metadata_path):\n",
    "        metadata_df = pd.read_csv(metadata_path)\n",
    "        total_files = len(metadata_df)\n",
    "        for rep_id, data_df, label in tqdm(data_loader, total=total_files, desc=\"Loading files\"):\n",
    "            data_df['ID'] = rep_id\n",
    "            data_df['label_positive'] = label\n",
    "            df_list.append(data_df)\n",
    "    else:\n",
    "        search_pattern = os.path.join(data_dir, '*.tsv')\n",
    "        total_files = len(glob.glob(search_pattern))\n",
    "        for filename, data_df in tqdm(data_loader, total=total_files, desc=\"Loading files\"):\n",
    "            data_df['ID'] = os.path.basename(filename).replace(\".tsv\", \"\")\n",
    "            df_list.append(data_df)\n",
    "\n",
    "    if not df_list:\n",
    "        print(\"Warning: No data files were loaded.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    full_dataset_df = pd.concat(df_list, ignore_index=True)\n",
    "    return full_dataset_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ffa8c6c",
   "metadata": {},
   "source": [
    "## Combined K-mer Encoding with Memory Management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f49b0cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LC: Major change made here \n",
    "def load_and_encode_kmers_combined(data_dir: str, k_list: List[int] = [3, 4], \n",
    "                                   min_kmer_count: int = 2,\n",
    "                                   batch_size: int = 100) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Loading and combined k-mer encoding of repertoire data.\n",
    "    \n",
    "    Memory-aware approach:\n",
    "    - Process files in batches\n",
    "    - Filter k-mers that appear less than min_kmer_count times (reduces feature space)\n",
    "    - Combine features from multiple k values\n",
    "    - Explicit garbage collection to manage memory\n",
    "\n",
    "    Args:\n",
    "        data_dir: Path to data directory\n",
    "        k_list: List of k-mer lengths to use (e.g., [3, 4])\n",
    "        min_kmer_count: Minimum count threshold for k-mers (filters rare k-mers)\n",
    "        batch_size: Number of files to process before saving intermediate results\n",
    "\n",
    "    Returns:\n",
    "        Tuple of (encoded_features_df, metadata_df)\n",
    "    \"\"\"\n",
    "    metadata_path = os.path.join(data_dir, 'metadata.csv')\n",
    "    data_loader = load_data_generator(data_dir=data_dir)\n",
    "\n",
    "    repertoire_features = []\n",
    "    metadata_records = []\n",
    "    \n",
    "    # Global k-mer counter to track which k-mers are actually used\n",
    "    global_kmer_counts = Counter()\n",
    "\n",
    "    search_pattern = os.path.join(data_dir, '*.tsv')\n",
    "    total_files = len(glob.glob(search_pattern))\n",
    "\n",
    "    print(f\"\\n[K-mer Encoding] Processing {total_files} files with k-values: {k_list}\")\n",
    "    print(f\"[K-mer Encoding] Min k-mer count threshold: {min_kmer_count}\")\n",
    "    \n",
    "    # First pass: collect all k-mers to identify frequent ones\n",
    "    print(\"\\n[K-mer Encoding] First pass: collecting k-mer frequencies...\")\n",
    "    data_loader = load_data_generator(data_dir=data_dir)\n",
    "    \n",
    "    file_count = 0\n",
    "    for item in tqdm(data_loader, total=total_files, desc=\"Collecting k-mer frequencies\"):\n",
    "        if os.path.exists(metadata_path):\n",
    "            rep_id, data_df, label = item\n",
    "        else:\n",
    "            filename, data_df = item\n",
    "            rep_id = os.path.basename(filename).replace(\".tsv\", \"\")\n",
    "            label = None\n",
    "\n",
    "        for seq in data_df['junction_aa'].dropna():\n",
    "            for k in k_list:\n",
    "                for i in range(len(seq) - k + 1):\n",
    "                    global_kmer_counts[seq[i:i + k]] += 1\n",
    "\n",
    "        del data_df\n",
    "        file_count += 1\n",
    "        \n",
    "        # Periodic garbage collection\n",
    "        if file_count % batch_size == 0:\n",
    "            gc.collect()\n",
    "            MemoryMonitor.log_memory(f\"After {file_count} files\")\n",
    "\n",
    "    # Filter to keep only frequent k-mers\n",
    "    frequent_kmers = {kmer for kmer, count in global_kmer_counts.items() if count >= min_kmer_count}\n",
    "    print(f\"\\n[K-mer Encoding] Total unique k-mers: {len(global_kmer_counts)}\")\n",
    "    print(f\"[K-mer Encoding] Frequent k-mers (count >= {min_kmer_count}): {len(frequent_kmers)}\")\n",
    "    print(f\"[K-mer Encoding] Memory reduction: {(1 - len(frequent_kmers)/len(global_kmer_counts))*100:.1f}%\")\n",
    "\n",
    "    # Second pass: encode using only frequent k-mers\n",
    "    print(\"\\n[K-mer Encoding] Second pass: encoding features...\")\n",
    "    data_loader = load_data_generator(data_dir=data_dir)\n",
    "    file_count = 0\n",
    "    \n",
    "    for item in tqdm(data_loader, total=total_files, desc=f\"Encoding {k_list}-mers\"):\n",
    "        if os.path.exists(metadata_path):\n",
    "            rep_id, data_df, label = item\n",
    "        else:\n",
    "            filename, data_df = item\n",
    "            rep_id = os.path.basename(filename).replace(\".tsv\", \"\")\n",
    "            label = None\n",
    "\n",
    "        # Count only frequent k-mers\n",
    "        kmer_counts = {}\n",
    "        for seq in data_df['junction_aa'].dropna():\n",
    "            for k in k_list:\n",
    "                for i in range(len(seq) - k + 1):\n",
    "                    kmer = seq[i:i + k]\n",
    "                    if kmer in frequent_kmers:\n",
    "                        kmer_counts[kmer] = kmer_counts.get(kmer, 0) + 1\n",
    "\n",
    "        repertoire_features.append({\n",
    "            'ID': rep_id,\n",
    "            **kmer_counts\n",
    "        })\n",
    "\n",
    "        metadata_record = {'ID': rep_id}\n",
    "        # Always add label_positive (even if None) to ensure consistency\n",
    "        metadata_record['label_positive'] = label\n",
    "        metadata_records.append(metadata_record)\n",
    "\n",
    "        del data_df, kmer_counts\n",
    "        file_count += 1\n",
    "        \n",
    "        # Periodic garbage collection and memory logging\n",
    "        if file_count % batch_size == 0:\n",
    "            gc.collect()\n",
    "            MemoryMonitor.log_memory(f\"After encoding {file_count} files\")\n",
    "\n",
    "    features_df = pd.DataFrame(repertoire_features).fillna(0).set_index('ID')\n",
    "    metadata_df = pd.DataFrame(metadata_records)\n",
    "    \n",
    "    print(f\"\\n[K-mer Encoding] Final feature matrix shape: {features_df.shape}\")\n",
    "    MemoryMonitor.log_memory(\"After encoding complete\")\n",
    "\n",
    "    return features_df, metadata_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "513887c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This chunck is the same as basline code template provided\n",
    "\n",
    "\n",
    "def save_tsv(df: pd.DataFrame, path: str):\n",
    "    os.makedirs(os.path.dirname(path), exist_ok=True)\n",
    "    df.to_csv(path, sep='\\t', index=False)\n",
    "\n",
    "\n",
    "def get_repertoire_ids(data_dir: str) -> list:\n",
    "    \"\"\"\n",
    "    Retrieves repertoire IDs from the metadata file or filenames in the directory.\n",
    "\n",
    "    Args:\n",
    "        data_dir (str): The path to the data directory.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of repertoire IDs.\n",
    "    \"\"\"\n",
    "    metadata_path = os.path.join(data_dir, 'metadata.csv')\n",
    "\n",
    "    if os.path.exists(metadata_path):\n",
    "        metadata_df = pd.read_csv(metadata_path)\n",
    "        repertoire_ids = metadata_df['repertoire_id'].tolist()\n",
    "    else:\n",
    "        search_pattern = os.path.join(data_dir, '*.tsv')\n",
    "        tsv_files = glob.glob(search_pattern)\n",
    "        repertoire_ids = [os.path.basename(f).replace('.tsv', '') for f in sorted(tsv_files)]\n",
    "\n",
    "    return repertoire_ids\n",
    "\n",
    "\n",
    "def validate_dirs_and_files(train_dir: str, test_dirs: List[str], out_dir: str) -> None:\n",
    "    assert os.path.isdir(train_dir), f\"Train directory `{train_dir}` does not exist.\"\n",
    "    train_tsvs = glob.glob(os.path.join(train_dir, \"*.tsv\"))\n",
    "    assert train_tsvs, f\"No .tsv files found in train directory `{train_dir}`.\"\n",
    "    metadata_path = os.path.join(train_dir, \"metadata.csv\")\n",
    "    assert os.path.isfile(metadata_path), f\"`metadata.csv` not found in train directory `{train_dir}`.\"\n",
    "\n",
    "    for test_dir in test_dirs:\n",
    "        assert os.path.isdir(test_dir), f\"Test directory `{test_dir}` does not exist.\"\n",
    "        test_tsvs = glob.glob(os.path.join(test_dir, \"*.tsv\"))\n",
    "        assert test_tsvs, f\"No .tsv files found in test directory `{test_dir}`.\"\n",
    "\n",
    "    try:\n",
    "        os.makedirs(out_dir, exist_ok=True)\n",
    "        test_file = os.path.join(out_dir, \"test_write_permission.tmp\")\n",
    "        with open(test_file, \"w\") as f:\n",
    "            f.write(\"test\")\n",
    "        os.remove(test_file)\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to create or write to output directory `{out_dir}`: {e}\")\n",
    "        sys.exit(1)\n",
    "\n",
    "\n",
    "def concatenate_output_files(out_dir: str) -> None:\n",
    "    \"\"\"\n",
    "    Concatenates all test predictions and important sequences TSV files from the output directory.\n",
    "\n",
    "    This function finds all files matching the patterns:\n",
    "    - *_test_predictions.tsv\n",
    "    - *_important_sequences.tsv\n",
    "\n",
    "    and concatenates them to match the expected output format of submissions.csv.\n",
    "\n",
    "    Args:\n",
    "        out_dir (str): Path to the output directory containing the TSV files.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Concatenated DataFrame with predictions followed by important sequences.\n",
    "                     Columns: ['ID', 'dataset', 'label_positive_probability', 'junction_aa', 'v_call', 'j_call']\n",
    "    \"\"\"\n",
    "    predictions_pattern = os.path.join(out_dir, '*_test_predictions.tsv')\n",
    "    sequences_pattern = os.path.join(out_dir, '*_important_sequences.tsv')\n",
    "\n",
    "    predictions_files = sorted(glob.glob(predictions_pattern))\n",
    "    sequences_files = sorted(glob.glob(sequences_pattern))\n",
    "\n",
    "    df_list = []\n",
    "\n",
    "    for pred_file in predictions_files:\n",
    "        try:\n",
    "            df = pd.read_csv(pred_file, sep='\\t')\n",
    "            df_list.append(df)\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: Could not read predictions file '{pred_file}'. Error: {e}. Skipping.\")\n",
    "            continue\n",
    "\n",
    "    for seq_file in sequences_files:\n",
    "        try:\n",
    "            df = pd.read_csv(seq_file, sep='\\t')\n",
    "            df_list.append(df)\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: Could not read sequences file '{seq_file}'. Error: {e}. Skipping.\")\n",
    "            continue\n",
    "\n",
    "    if not df_list:\n",
    "        print(\"Warning: No output files were found to concatenate.\")\n",
    "        concatenated_df = pd.DataFrame(\n",
    "            columns=['ID', 'dataset', 'label_positive_probability', 'junction_aa', 'v_call', 'j_call'])\n",
    "    else:\n",
    "        concatenated_df = pd.concat(df_list, ignore_index=True)\n",
    "    \n",
    "    submissions_file = os.path.join(out_dir, 'submissions.csv')\n",
    "    concatenated_df.to_csv(submissions_file, index=False)\n",
    "    print(f\"Concatenated output written to `{submissions_file}`.\")\n",
    "\n",
    "\n",
    "def get_dataset_pairs(train_dir: str, test_dir: str) -> List[Tuple[str, List[str]]]:\n",
    "    \"\"\"Returns list of (train_path, [test_paths]) tuples for dataset pairs.\"\"\"\n",
    "    test_groups = defaultdict(list)\n",
    "    for test_name in sorted(os.listdir(test_dir)):\n",
    "        if test_name.startswith(\"test_dataset_\"):\n",
    "            base_id = test_name.replace(\"test_dataset_\", \"\").split(\"_\")[0]\n",
    "            test_groups[base_id].append(os.path.join(test_dir, test_name))\n",
    "\n",
    "    pairs = []\n",
    "    for train_name in sorted(os.listdir(train_dir)):\n",
    "        if train_name.startswith(\"train_dataset_\"):\n",
    "            train_id = train_name.replace(\"train_dataset_\", \"\")\n",
    "            train_path = os.path.join(train_dir, train_name)\n",
    "            pairs.append((train_path, test_groups.get(train_id, [])))\n",
    "\n",
    "    return pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da8c4243",
   "metadata": {},
   "source": [
    "## L1-Regularized Classifier with Memory-Aware Sequence Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d058009d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KmerClassifier:\n",
    "    \"\"\"L1-regularized logistic regression for combined k-mer count data.\"\"\"\n",
    "\n",
    "    def __init__(self, c_values=None, cv_folds=5,\n",
    "                 opt_metric='balanced_accuracy', random_state=None, n_jobs=1):\n",
    "        if c_values is None:\n",
    "            c_values = [1, 0.1, 0.05, 0.03]\n",
    "        self.c_values = c_values\n",
    "        self.cv_folds = cv_folds\n",
    "        self.opt_metric = opt_metric\n",
    "        self.random_state = random_state if random_state is not None else 42\n",
    "        self.n_jobs = n_jobs\n",
    "        self.best_C_ = None\n",
    "        self.best_score_ = None\n",
    "        self.cv_results_ = None\n",
    "        self.model_ = None\n",
    "        self.feature_names_ = None\n",
    "        self.val_score_ = None\n",
    "\n",
    "    def _make_pipeline(self, C):\n",
    "        \"\"\"Create standardization + L1 logistic regression pipeline.\"\"\"\n",
    "        return Pipeline([\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('classifier', LogisticRegression(\n",
    "                penalty='l1', C=C, solver='liblinear',\n",
    "                random_state=self.random_state, max_iter=1000\n",
    "            ))\n",
    "        ])\n",
    "\n",
    "    def _get_scorer(self):\n",
    "        \"\"\"Get scoring function for optimization.\"\"\"\n",
    "        if self.opt_metric == 'balanced_accuracy':\n",
    "            return 'balanced_accuracy'\n",
    "        elif self.opt_metric == 'roc_auc':\n",
    "            return 'roc_auc'\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown metric: {self.opt_metric}\")\n",
    "\n",
    "    def tune_and_fit(self, X, y, val_size=0.0):\n",
    "        \"\"\"Perform CV tuning on all data (no validation split) to use all available training data.\"\"\"\n",
    "\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            self.feature_names_ = X.columns.tolist()\n",
    "            X = X.values\n",
    "        if isinstance(y, pd.Series):\n",
    "            y = y.values\n",
    "\n",
    "        if val_size > 0:\n",
    "            X_train, X_val, y_train, y_val = train_test_split(\n",
    "                X, y, test_size=val_size, random_state=self.random_state, stratify=y)\n",
    "        else:\n",
    "            X_train, y_train = X, y\n",
    "            X_val, y_val = None, None\n",
    "\n",
    "        cv = StratifiedKFold(n_splits=self.cv_folds, shuffle=True,\n",
    "                             random_state=self.random_state)\n",
    "        scorer = self._get_scorer()\n",
    "\n",
    "        results = []\n",
    "        for C in self.c_values:\n",
    "            pipeline = self._make_pipeline(C)\n",
    "            scores = cross_val_score(pipeline, X_train, y_train, cv=cv, scoring=scorer,\n",
    "                                     n_jobs=self.n_jobs)\n",
    "            results.append({\n",
    "                'C': C,\n",
    "                'mean_score': scores.mean(),\n",
    "                'std_score': scores.std(),\n",
    "                'scores': scores\n",
    "            })\n",
    "\n",
    "        self.cv_results_ = pd.DataFrame(results)\n",
    "        best_idx = self.cv_results_['mean_score'].idxmax()\n",
    "        self.best_C_ = self.cv_results_.loc[best_idx, 'C']\n",
    "        self.best_score_ = self.cv_results_.loc[best_idx, 'mean_score']\n",
    "\n",
    "        print(f\"Best C: {self.best_C_} (CV {self.opt_metric}: {self.best_score_:.4f})\")\n",
    "\n",
    "        # Fit on training split with best hyperparameter\n",
    "        self.model_ = self._make_pipeline(self.best_C_)\n",
    "        self.model_.fit(X_train, y_train)\n",
    "\n",
    "        if X_val is not None:\n",
    "            if scorer == 'balanced_accuracy':\n",
    "                self.val_score_ = balanced_accuracy_score(y_val, self.model_.predict(X_val))\n",
    "            else:  # roc_auc\n",
    "                self.val_score_ = roc_auc_score(y_val, self.model_.predict_proba(X_val)[:, 1])\n",
    "            print(f\"Validation {self.opt_metric}: {self.val_score_:.4f}\")\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"Predict class probabilities.\"\"\"\n",
    "        if self.model_ is None:\n",
    "            raise ValueError(\"Model not fitted.\")\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            X = X.values\n",
    "        return self.model_.predict_proba(X)[:, 1]\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"Predict class labels.\"\"\"\n",
    "        if self.model_ is None:\n",
    "            raise ValueError(\"Model not fitted.\")\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            X = X.values\n",
    "        return self.model_.predict(X)\n",
    "\n",
    "    def get_feature_importance(self):\n",
    "        \"\"\"Get feature importance from L1 coefficients.\"\"\"\n",
    "        if self.model_ is None:\n",
    "            raise ValueError(\"Model not fitted.\")\n",
    "\n",
    "        coef = self.model_.named_steps['classifier'].coef_[0]\n",
    "\n",
    "        if self.feature_names_ is not None:\n",
    "            feature_names = self.feature_names_\n",
    "        else:\n",
    "            feature_names = [f\"feature_{i}\" for i in range(len(coef))]\n",
    "\n",
    "        importance_df = pd.DataFrame({\n",
    "            'feature': feature_names,\n",
    "            'coefficient': coef,\n",
    "            'abs_coefficient': np.abs(coef)\n",
    "        })\n",
    "\n",
    "        importance_df = importance_df.sort_values('abs_coefficient', ascending=False)\n",
    "\n",
    "        return importance_df\n",
    "\n",
    "    # changed this one \n",
    "    def score_all_sequences(self, sequences_df, sequence_col='junction_aa', \n",
    "                           batch_size=500, k_list=[3, 4]):\n",
    "        \"\"\"\n",
    "        Score all sequences using model coefficients (vectorized, batched, memory-aware).\n",
    "\n",
    "        Parameters:\n",
    "            sequences_df: DataFrame with unique sequences\n",
    "            sequence_col: Column name containing sequences\n",
    "            batch_size: Number of sequences to process in each batch\n",
    "            k_list: List of k-mer sizes used in training\n",
    "\n",
    "        Returns:\n",
    "            DataFrame with added 'importance_score' column\n",
    "        \"\"\"\n",
    "        if self.model_ is None:\n",
    "            raise ValueError(\"Model not fitted.\")\n",
    "\n",
    "        scaler = self.model_.named_steps['scaler']\n",
    "        coefficients = self.model_.named_steps['classifier'].coef_[0]\n",
    "        coefficients = coefficients / scaler.scale_\n",
    "\n",
    "        kmer_to_index = {kmer: idx for idx, kmer in enumerate(self.feature_names_)}\n",
    "\n",
    "        scores = []\n",
    "        total_seqs = len(sequences_df)\n",
    "        sequences_list = sequences_df[sequence_col].tolist()\n",
    "        \n",
    "        # Process in batches for better performance and memory efficiency\n",
    "        for batch_start in tqdm(range(0, total_seqs, batch_size), desc=\"Scoring sequences (batched)\"):\n",
    "            batch_end = min(batch_start + batch_size, total_seqs)\n",
    "            batch_scores = []\n",
    "            \n",
    "            for seq in sequences_list[batch_start:batch_end]:\n",
    "                counts = np.zeros(len(kmer_to_index), dtype=np.uint8)\n",
    "                # Extract all k-mers from sequence\n",
    "                for k in k_list:\n",
    "                    for i in range(max(0, len(seq) - k + 1)):\n",
    "                        kmer = seq[i:i + k]\n",
    "                        if kmer in kmer_to_index:\n",
    "                            counts[kmer_to_index[kmer]] = 1\n",
    "                batch_scores.append(np.dot(counts, coefficients))\n",
    "            \n",
    "            scores.extend(batch_scores)\n",
    "            \n",
    "            # Periodic garbage collection\n",
    "            if (batch_start // batch_size) % 10 == 0:\n",
    "                gc.collect()\n",
    "\n",
    "        result_df = sequences_df.copy()\n",
    "        result_df['importance_score'] = scores\n",
    "        return result_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "483f9321",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d2d7d1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same as basline code template provided\n",
    "def prepare_data(X_df, labels_df, id_col='ID', label_col='label_positive'):\n",
    "    \"\"\"\n",
    "    Merge feature matrix with labels, ensuring alignment.\n",
    "\n",
    "    Parameters:\n",
    "        X_df: DataFrame with samples as rows (index contains IDs)\n",
    "        labels_df: DataFrame with ID column and label column\n",
    "        id_col: Name of ID column in labels_df\n",
    "        label_col: Name of label column in labels_df\n",
    "\n",
    "    Returns:\n",
    "        X: Feature matrix aligned with labels\n",
    "        y: Binary labels\n",
    "        common_ids: IDs that were kept\n",
    "    \"\"\"\n",
    "    if id_col in labels_df.columns:\n",
    "        labels_indexed = labels_df.set_index(id_col)[label_col]\n",
    "    else:\n",
    "        # Assume labels_df index is already the ID\n",
    "        labels_indexed = labels_df[label_col]\n",
    "\n",
    "    common_ids = X_df.index.intersection(labels_indexed.index)\n",
    "\n",
    "    if len(common_ids) == 0:\n",
    "        raise ValueError(\"No common IDs found between feature matrix and labels\")\n",
    "\n",
    "    X = X_df.loc[common_ids]\n",
    "    y = labels_indexed.loc[common_ids]\n",
    "\n",
    "    print(f\"Aligned {len(common_ids)} samples with labels\")\n",
    "\n",
    "    return X, y, common_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3def7091",
   "metadata": {},
   "source": [
    "## Main Predictor Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fbad8c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImmuneStatePredictor:\n",
    "    \"\"\"\n",
    "    A template for predicting immune states from TCR repertoire data.\n",
    "\n",
    "    Participants should implement the logic for training, prediction, and\n",
    "\n",
    "    sequence identification within this class.\n",
    "\n",
    "    Immune state predictor using combined k-mer encoding (3-mers + 4-mers).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, k_list=[3, 4], min_kmer_count=2, n_jobs=1, device='cpu', **kwargs):\n",
    "        \"\"\"\n",
    "        Initializes the predictor.\n",
    "\n",
    "        Args:\n",
    "            k_list: List of k-mer lengths to use (default: [3, 4])\n",
    "            min_kmer_count: Minimum count threshold for k-mers (memory optimization)\n",
    "            n_jobs: Number of CPU cores to use\n",
    "            device: Device for computation ('cpu' or 'cuda')\n",
    "        \"\"\"\n",
    "        self.k_list = k_list\n",
    "        self.min_kmer_count = min_kmer_count\n",
    "        self.train_ids_ = None\n",
    "        total_cores = os.cpu_count()\n",
    "        if n_jobs == -1:\n",
    "            self.n_jobs = total_cores\n",
    "        else:\n",
    "            self.n_jobs = min(n_jobs, total_cores)\n",
    "        self.device = device\n",
    "        if device == 'cuda' and not torch.cuda.is_available():\n",
    "            print(\"Warning: 'cuda' was requested but is not available. Falling back to 'cpu'.\")\n",
    "            self.device = 'cpu'\n",
    "\n",
    "        self.model = None\n",
    "        self.important_sequences_ = None\n",
    "\n",
    "    def fit(self, train_dir_path: str):\n",
    "        \"\"\"\n",
    "        Trains the model on the provided training data using ALL available data.\n",
    "\n",
    "        Args:\n",
    "            train_dir_path (str): Path to the directory with training TSV files.\n",
    "\n",
    "        Returns:\n",
    "            self: The fitted predictor instance.\n",
    "        \"\"\"\n",
    "        print(f\"\\n[Training] Starting fit on {train_dir_path}\")\n",
    "        print(f\"[Training] K-mer sizes: {self.k_list}\")\n",
    "        print(f\"[Training] Min k-mer count: {self.min_kmer_count}\")\n",
    "\n",
    "        # Load and encode k-mers with combined k values\n",
    "        X_train_df, y_train_df = load_and_encode_kmers_combined(\n",
    "            train_dir_path, \n",
    "            k_list=self.k_list,\n",
    "            min_kmer_count=self.min_kmer_count\n",
    "        )\n",
    "\n",
    "        X_train, y_train, train_ids = prepare_data(X_train_df, y_train_df,\n",
    "                                                   id_col='ID', label_col='label_positive')\n",
    "\n",
    "        self.model = KmerClassifier(\n",
    "            c_values=[1, 0.2, 0.1, 0.05, 0.03],\n",
    "            cv_folds=5,\n",
    "            opt_metric='roc_auc',\n",
    "            random_state=42, # Baseline used 123\n",
    "            n_jobs=self.n_jobs\n",
    "        )\n",
    "\n",
    "        # Use all training data (val_size=0.0) to maximize training data usage; seems better for final model\n",
    "        self.model.tune_and_fit(X_train, y_train, val_size=0.0)\n",
    "\n",
    "        self.train_ids_ = train_ids\n",
    "\n",
    "        # Identify important sequences\n",
    "        self.important_sequences_ = self.identify_associated_sequences(\n",
    "            train_dir_path=train_dir_path, \n",
    "            top_k=50000  # Updated to 50k for submission\n",
    "        )\n",
    "\n",
    "        print(\"[Training] Training complete.\")\n",
    "        MemoryMonitor.log_memory(\"After training\")\n",
    "        return self\n",
    "\n",
    "    def predict_proba(self, test_dir_path: str) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Predicts probabilities for examples in the provided path.\n",
    "\n",
    "        Args:\n",
    "            test_dir_path (str): Path to the directory with test TSV files.\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: Predictions with proper format.\n",
    "        \"\"\"\n",
    "        print(f\"\\n[Prediction] Making predictions for {test_dir_path}...\")\n",
    "        if self.model is None:\n",
    "            raise RuntimeError(\"The model has not been fitted yet. Please call `fit` first.\")\n",
    "\n",
    "        X_test_df, _ = load_and_encode_kmers_combined(\n",
    "            test_dir_path,\n",
    "            k_list=self.k_list,\n",
    "            min_kmer_count=1  # Lower threshold for test data\n",
    "        )\n",
    "\n",
    "        if self.model.feature_names_ is not None:\n",
    "            X_test_df = X_test_df.reindex(columns=self.model.feature_names_, fill_value=0)\n",
    "\n",
    "        repertoire_ids = X_test_df.index.tolist()\n",
    "\n",
    "        # Make predictions\n",
    "        probabilities = self.model.predict_proba(X_test_df)\n",
    "\n",
    "        predictions_df = pd.DataFrame({\n",
    "            'ID': repertoire_ids,\n",
    "            'dataset': [os.path.basename(test_dir_path)] * len(repertoire_ids),\n",
    "            'label_positive_probability': probabilities\n",
    "        })\n",
    "\n",
    "        # Add placeholder columns for output format compatibility\n",
    "        predictions_df['junction_aa'] = -999.0\n",
    "        predictions_df['v_call'] = -999.0\n",
    "        predictions_df['j_call'] = -999.0\n",
    "\n",
    "        predictions_df = predictions_df[['ID', 'dataset', 'label_positive_probability', 'junction_aa', 'v_call', 'j_call']]\n",
    "\n",
    "        print(f\"[Prediction] Completed predictions for {len(repertoire_ids)} examples.\")\n",
    "        MemoryMonitor.log_memory(\"After prediction\")\n",
    "        return predictions_df\n",
    "\n",
    "    def identify_associated_sequences(self, train_dir_path: str, top_k: int = 50000) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Identifies the top k important sequences from the training data, ranked by importance score.\n",
    "\n",
    "        Args:\n",
    "            top_k (int): Number of top sequences to return\n",
    "            train_dir_path (str): Path to training directory\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: Top important sequences with scores, ranked by importance_score descending\n",
    "        \"\"\"\n",
    "        print(f\"\\n[Sequence Identification] Identifying top {top_k} sequences...\")\n",
    "        dataset_name = os.path.basename(train_dir_path)\n",
    "\n",
    "        # Load full dataset to get unique sequences\n",
    "        full_df = load_full_dataset(train_dir_path)\n",
    "        unique_seqs = full_df[['junction_aa', 'v_call', 'j_call']].drop_duplicates().reset_index(drop=True)\n",
    "        \n",
    "        print(f\"[Sequence Identification] Scoring {len(unique_seqs)} unique sequences...\")\n",
    "\n",
    "        # Baseline: all_sequences_scored = self.model.score_all_sequences(unique_seqs, sequence_col='junction_aa')\n",
    "        all_sequences_scored = self.model.score_all_sequences(\n",
    "            unique_seqs, \n",
    "            sequence_col='junction_aa',\n",
    "            batch_size=500,\n",
    "            k_list=self.k_list\n",
    "        )\n",
    "\n",
    "        top_sequences_df = all_sequences_scored.nlargest(top_k, 'importance_score')\n",
    "        top_sequences_df = top_sequences_df[['junction_aa', 'v_call', 'j_call']]\n",
    "        top_sequences_df['dataset'] = dataset_name\n",
    "        top_sequences_df['ID'] = range(1, len(top_sequences_df)+1)\n",
    "        top_sequences_df['ID'] = top_sequences_df['dataset'] + '_seq_top_' + top_sequences_df['ID'].astype(str)\n",
    "        top_sequences_df['label_positive_probability'] = -999.0# to enable compatibility with the expected output format\n",
    "        top_sequences_df = top_sequences_df[['ID', 'dataset', 'label_positive_probability', 'junction_aa', 'v_call', 'j_call']]\n",
    "\n",
    "        print(f\"[Sequence Identification] Identified {len(top_sequences_df)} top sequences ranked by importance score.\")\n",
    "        MemoryMonitor.log_memory(\"After sequence identification\")\n",
    "        return top_sequences_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cee6c3a",
   "metadata": {},
   "source": [
    "## Pipeline Execution Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c21451cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _train_predictor(predictor: ImmuneStatePredictor, train_dir: str):\n",
    "    \"\"\"Trains the predictor on the training data.\"\"\"\n",
    "    print(f\"\\nFitting model on examples in `{train_dir}`...\")\n",
    "    predictor.fit(train_dir)\n",
    "\n",
    "\n",
    "def _save_model(predictor: ImmuneStatePredictor, out_dir: str, train_dir: str) -> None:\n",
    "    \"\"\"Saves the trained model to a pickle file.\"\"\"\n",
    "    if predictor.model is None:\n",
    "        raise ValueError(\"No trained model available to save\")\n",
    "    \n",
    "    model_path = os.path.join(out_dir, f\"{os.path.basename(train_dir)}_model.pkl\")\n",
    "    with open(model_path, 'wb') as f:\n",
    "        pickle.dump(predictor.model, f)\n",
    "    print(f\"Trained model saved to `{model_path}`.\")\n",
    "\n",
    "\n",
    "def _generate_predictions(predictor: ImmuneStatePredictor, test_dirs: List[str]) -> pd.DataFrame:\n",
    "    \"\"\"Generates predictions for all test directories and concatenates them.\"\"\"\n",
    "    all_preds = []\n",
    "    for test_dir in test_dirs:\n",
    "        print(f\"\\nPredicting on examples in `{test_dir}`...\")\n",
    "        preds = predictor.predict_proba(test_dir)\n",
    "        if preds is not None and not preds.empty:\n",
    "            all_preds.append(preds)\n",
    "        else:\n",
    "            print(f\"Warning: No predictions returned for {test_dir}\")\n",
    "    if all_preds:\n",
    "        return pd.concat(all_preds, ignore_index=True)\n",
    "    return pd.DataFrame()\n",
    "\n",
    "\n",
    "def _save_predictions(predictions: pd.DataFrame, out_dir: str, train_dir: str) -> None:\n",
    "    \"\"\"Saves predictions to a TSV file.\"\"\"\n",
    "    if predictions.empty:\n",
    "        raise ValueError(\"No predictions to save - predictions DataFrame is empty\")\n",
    "\n",
    "    preds_path = os.path.join(out_dir, f\"{os.path.basename(train_dir)}_test_predictions.tsv\")\n",
    "    save_tsv(predictions, preds_path)\n",
    "    print(f\"Predictions written to `{preds_path}`.\")\n",
    "\n",
    "\n",
    "def _save_important_sequences(predictor: ImmuneStatePredictor, out_dir: str, train_dir: str) -> None:\n",
    "    \"\"\"Saves important sequences to a TSV file.\"\"\"\n",
    "    seqs = predictor.important_sequences_\n",
    "    if seqs is None or seqs.empty:\n",
    "        raise ValueError(\"No important sequences available to save\")\n",
    "\n",
    "    seqs_path = os.path.join(out_dir, f\"{os.path.basename(train_dir)}_important_sequences.tsv\")\n",
    "    save_tsv(seqs, seqs_path)\n",
    "    print(f\"Important sequences written to `{seqs_path}`.\")\n",
    "\n",
    "\n",
    "def main(train_dir: str, test_dirs: List[str], out_dir: str, n_jobs: int, device: str, \n",
    "         k_list: List[int] = [3, 4], min_kmer_count: int = 2, save_model: bool = True) -> None:\n",
    "    \"\"\"Main pipeline for training and prediction.\"\"\"\n",
    "    validate_dirs_and_files(train_dir, test_dirs, out_dir)\n",
    "\n",
    "    # LC: Changed here to use the updated class\n",
    "    predictor = ImmuneStatePredictor(\n",
    "        k_list=k_list,\n",
    "        min_kmer_count=min_kmer_count,\n",
    "        n_jobs=n_jobs,\n",
    "        device=device\n",
    "    )\n",
    "    _train_predictor(predictor, train_dir)\n",
    "    \n",
    "    # Save the trained model\n",
    "    if save_model:\n",
    "        _save_model(predictor, out_dir, train_dir)\n",
    "    \n",
    "    predictions = _generate_predictions(predictor, test_dirs)\n",
    "    _save_predictions(predictions, out_dir, train_dir)\n",
    "    _save_important_sequences(predictor, out_dir, train_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1438fb4a",
   "metadata": {},
   "source": [
    "## Execution: Test on Small Dataset First"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a72ab5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results will be saved to: /home/ccdd/Documents/airr-ml/results/1122_3_4_mer_min_kmer_count_20\n",
      "\n",
      "Found 8 total datasets\n",
      "Processing all datasets...\n",
      "\n",
      "[Memory] Before processing - Process: 0.52GB, Available: 15.41GB\n",
      "\n",
      "================================================================================\n",
      "Processing Dataset 8\n",
      "================================================================================\n",
      "\n",
      "Fitting model on examples in `/home/ccdd/Documents/airr-ml/data/train_datasets/train_dataset_8`...\n",
      "\n",
      "[Training] Starting fit on /home/ccdd/Documents/airr-ml/data/train_datasets/train_dataset_8\n",
      "[Training] K-mer sizes: [3, 4]\n",
      "[Training] Min k-mer count: 20\n",
      "\n",
      "[K-mer Encoding] Processing 908 files with k-values: [3, 4]\n",
      "[K-mer Encoding] Min k-mer count threshold: 20\n",
      "\n",
      "[K-mer Encoding] First pass: collecting k-mer frequencies...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting k-mer frequencies:   0%|          | 0/908 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting k-mer frequencies:  11%|█         | 100/908 [01:04<08:43,  1.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory] After 100 files - Process: 0.57GB, Available: 16.42GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting k-mer frequencies:  22%|██▏       | 200/908 [02:07<07:18,  1.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory] After 200 files - Process: 0.58GB, Available: 16.49GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting k-mer frequencies:  33%|███▎      | 300/908 [03:10<07:25,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory] After 300 files - Process: 0.58GB, Available: 16.48GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting k-mer frequencies:  44%|████▍     | 400/908 [04:13<05:48,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory] After 400 files - Process: 0.58GB, Available: 16.49GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting k-mer frequencies:  55%|█████▌    | 500/908 [05:13<03:47,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory] After 500 files - Process: 0.58GB, Available: 16.48GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting k-mer frequencies:  66%|██████▌   | 600/908 [06:16<03:14,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory] After 600 files - Process: 0.58GB, Available: 16.48GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting k-mer frequencies:  77%|███████▋  | 700/908 [07:20<02:36,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory] After 700 files - Process: 0.58GB, Available: 16.47GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting k-mer frequencies:  88%|████████▊ | 800/908 [08:23<01:03,  1.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory] After 800 files - Process: 0.58GB, Available: 16.49GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting k-mer frequencies:  99%|█████████▉| 900/908 [09:25<00:05,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory] After 900 files - Process: 0.59GB, Available: 16.49GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting k-mer frequencies: 100%|██████████| 908/908 [09:30<00:00,  1.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[K-mer Encoding] Total unique k-mers: 165711\n",
      "[K-mer Encoding] Frequent k-mers (count >= 20): 140803\n",
      "[K-mer Encoding] Memory reduction: 15.0%\n",
      "\n",
      "[K-mer Encoding] Second pass: encoding features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding [3, 4]-mers:  11%|█         | 100/908 [00:52<07:11,  1.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory] After encoding 100 files - Process: 1.13GB, Available: 15.94GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding [3, 4]-mers:  22%|██▏       | 200/908 [01:43<05:59,  1.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory] After encoding 200 files - Process: 1.66GB, Available: 15.42GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding [3, 4]-mers:  33%|███▎      | 300/908 [02:34<06:08,  1.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory] After encoding 300 files - Process: 2.19GB, Available: 14.87GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding [3, 4]-mers:  44%|████▍     | 400/908 [03:26<04:45,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory] After encoding 400 files - Process: 2.71GB, Available: 14.35GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding [3, 4]-mers:  55%|█████▌    | 500/908 [04:14<03:07,  2.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory] After encoding 500 files - Process: 3.21GB, Available: 13.85GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding [3, 4]-mers:  66%|██████▌   | 600/908 [05:06<02:39,  1.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory] After encoding 600 files - Process: 3.73GB, Available: 13.34GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding [3, 4]-mers:  77%|███████▋  | 700/908 [05:58<02:09,  1.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory] After encoding 700 files - Process: 4.26GB, Available: 12.79GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding [3, 4]-mers:  88%|████████▊ | 800/908 [06:49<00:52,  2.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory] After encoding 800 files - Process: 4.79GB, Available: 12.26GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding [3, 4]-mers:  99%|█████████▉| 900/908 [07:40<00:04,  1.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory] After encoding 900 files - Process: 5.32GB, Available: 11.73GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding [3, 4]-mers: 100%|██████████| 908/908 [07:44<00:00,  1.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[K-mer Encoding] Final feature matrix shape: (908, 140803)\n",
      "[Memory] After encoding complete - Process: 7.17GB, Available: 9.84GB\n",
      "Aligned 908 samples with labels\n",
      "Best C: 1.0 (CV roc_auc: 0.6867)\n",
      "\n",
      "[Sequence Identification] Identifying top 50000 sequences...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading files: 100%|██████████| 908/908 [00:51<00:00, 17.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Sequence Identification] Scoring 69535082 unique sequences...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring sequences (batched): 100%|██████████| 139071/139071 [6:04:46<00:00,  6.35it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Sequence Identification] Identified 50000 top sequences ranked by importance score.\n",
      "[Memory] After sequence identification - Process: 14.62GB, Available: 8.72GB\n",
      "[Training] Training complete.\n",
      "[Memory] After training - Process: 8.29GB, Available: 14.99GB\n",
      "Trained model saved to `/home/ccdd/Documents/airr-ml/results/1122_3_4_mer_min_kmer_count_20/train_dataset_8_model.pkl`.\n",
      "\n",
      "Predicting on examples in `/home/ccdd/Documents/airr-ml/data/test_datasets/test_dataset_8_1`...\n",
      "\n",
      "[Prediction] Making predictions for /home/ccdd/Documents/airr-ml/data/test_datasets/test_dataset_8_1...\n",
      "\n",
      "[K-mer Encoding] Processing 390 files with k-values: [3, 4]\n",
      "[K-mer Encoding] Min k-mer count threshold: 1\n",
      "\n",
      "[K-mer Encoding] First pass: collecting k-mer frequencies...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting k-mer frequencies:  26%|██▌       | 100/390 [01:05<03:27,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory] After 100 files - Process: 8.42GB, Available: 14.87GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting k-mer frequencies:  51%|█████▏    | 200/390 [02:13<01:57,  1.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory] After 200 files - Process: 8.42GB, Available: 14.90GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting k-mer frequencies:  77%|███████▋  | 300/390 [03:18<00:55,  1.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory] After 300 files - Process: 8.42GB, Available: 14.89GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting k-mer frequencies: 100%|██████████| 390/390 [04:18<00:00,  1.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[K-mer Encoding] Total unique k-mers: 162650\n",
      "[K-mer Encoding] Frequent k-mers (count >= 1): 162650\n",
      "[K-mer Encoding] Memory reduction: 0.0%\n",
      "\n",
      "[K-mer Encoding] Second pass: encoding features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding [3, 4]-mers:  26%|██▌       | 100/390 [00:55<02:54,  1.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory] After encoding 100 files - Process: 8.68GB, Available: 14.65GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding [3, 4]-mers:  51%|█████▏    | 200/390 [01:50<01:36,  1.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory] After encoding 200 files - Process: 8.86GB, Available: 14.47GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding [3, 4]-mers:  77%|███████▋  | 300/390 [02:43<00:45,  1.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory] After encoding 300 files - Process: 9.04GB, Available: 14.29GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding [3, 4]-mers: 100%|██████████| 390/390 [03:32<00:00,  1.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[K-mer Encoding] Final feature matrix shape: (390, 162650)\n",
      "[Memory] After encoding complete - Process: 10.67GB, Available: 12.56GB\n",
      "[Prediction] Completed predictions for 390 examples.\n",
      "[Memory] After prediction - Process: 10.87GB, Available: 12.36GB\n",
      "\n",
      "Predicting on examples in `/home/ccdd/Documents/airr-ml/data/test_datasets/test_dataset_8_2`...\n",
      "\n",
      "[Prediction] Making predictions for /home/ccdd/Documents/airr-ml/data/test_datasets/test_dataset_8_2...\n",
      "\n",
      "[K-mer Encoding] Processing 857 files with k-values: [3, 4]\n",
      "[K-mer Encoding] Min k-mer count threshold: 1\n",
      "\n",
      "[K-mer Encoding] First pass: collecting k-mer frequencies...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting k-mer frequencies:  12%|█▏        | 100/857 [00:30<03:53,  3.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory] After 100 files - Process: 10.87GB, Available: 12.45GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting k-mer frequencies:  23%|██▎       | 200/857 [01:01<03:25,  3.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory] After 200 files - Process: 10.87GB, Available: 12.44GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting k-mer frequencies:  35%|███▌      | 300/857 [01:31<02:56,  3.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory] After 300 files - Process: 10.87GB, Available: 12.44GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting k-mer frequencies:  47%|████▋     | 400/857 [02:01<02:22,  3.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory] After 400 files - Process: 10.87GB, Available: 12.45GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting k-mer frequencies:  58%|█████▊    | 500/857 [02:31<02:17,  2.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory] After 500 files - Process: 10.87GB, Available: 12.45GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting k-mer frequencies:  70%|███████   | 600/857 [03:02<01:20,  3.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory] After 600 files - Process: 10.87GB, Available: 12.45GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting k-mer frequencies:  82%|████████▏ | 700/857 [03:32<00:49,  3.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory] After 700 files - Process: 10.87GB, Available: 12.45GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting k-mer frequencies:  93%|█████████▎| 800/857 [04:02<00:16,  3.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory] After 800 files - Process: 10.87GB, Available: 12.44GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting k-mer frequencies: 100%|██████████| 857/857 [04:20<00:00,  3.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[K-mer Encoding] Total unique k-mers: 162448\n",
      "[K-mer Encoding] Frequent k-mers (count >= 1): 162448\n",
      "[K-mer Encoding] Memory reduction: 0.0%\n",
      "\n",
      "[K-mer Encoding] Second pass: encoding features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding [3, 4]-mers:  12%|█▏        | 100/857 [00:26<03:22,  3.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory] After encoding 100 files - Process: 10.87GB, Available: 12.45GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding [3, 4]-mers:  23%|██▎       | 201/857 [00:51<02:42,  4.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory] After encoding 200 files - Process: 10.87GB, Available: 12.45GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding [3, 4]-mers:  35%|███▌      | 300/857 [01:17<02:31,  3.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory] After encoding 300 files - Process: 10.87GB, Available: 12.45GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding [3, 4]-mers:  47%|████▋     | 400/857 [01:42<02:02,  3.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory] After encoding 400 files - Process: 10.87GB, Available: 12.45GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding [3, 4]-mers:  58%|█████▊    | 500/857 [02:07<01:57,  3.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory] After encoding 500 files - Process: 10.87GB, Available: 12.45GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding [3, 4]-mers:  70%|███████   | 600/857 [02:33<01:09,  3.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory] After encoding 600 files - Process: 10.87GB, Available: 12.45GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding [3, 4]-mers:  82%|████████▏ | 700/857 [02:58<00:42,  3.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory] After encoding 700 files - Process: 10.87GB, Available: 12.45GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding [3, 4]-mers:  93%|█████████▎| 800/857 [03:23<00:14,  4.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory] After encoding 800 files - Process: 10.90GB, Available: 12.43GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding [3, 4]-mers: 100%|██████████| 857/857 [03:38<00:00,  3.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[K-mer Encoding] Final feature matrix shape: (857, 162448)\n",
      "[Memory] After encoding complete - Process: 13.20GB, Available: 10.01GB\n",
      "[Prediction] Completed predictions for 857 examples.\n",
      "[Memory] After prediction - Process: 12.24GB, Available: 10.89GB\n",
      "\n",
      "Predicting on examples in `/home/ccdd/Documents/airr-ml/data/test_datasets/test_dataset_8_3`...\n",
      "\n",
      "[Prediction] Making predictions for /home/ccdd/Documents/airr-ml/data/test_datasets/test_dataset_8_3...\n",
      "\n",
      "[K-mer Encoding] Processing 390 files with k-values: [3, 4]\n",
      "[K-mer Encoding] Min k-mer count threshold: 1\n",
      "\n",
      "[K-mer Encoding] First pass: collecting k-mer frequencies...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting k-mer frequencies:  26%|██▌       | 100/390 [01:05<03:31,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory] After 100 files - Process: 12.24GB, Available: 11.07GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting k-mer frequencies:  51%|█████▏    | 200/390 [02:11<02:11,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory] After 200 files - Process: 12.24GB, Available: 11.05GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting k-mer frequencies:  77%|███████▋  | 300/390 [03:17<01:08,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory] After 300 files - Process: 12.24GB, Available: 11.06GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting k-mer frequencies: 100%|██████████| 390/390 [04:17<00:00,  1.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[K-mer Encoding] Total unique k-mers: 162650\n",
      "[K-mer Encoding] Frequent k-mers (count >= 1): 162650\n",
      "[K-mer Encoding] Memory reduction: 0.0%\n",
      "\n",
      "[K-mer Encoding] Second pass: encoding features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding [3, 4]-mers:  26%|██▌       | 100/390 [00:53<02:54,  1.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory] After encoding 100 files - Process: 12.24GB, Available: 11.08GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding [3, 4]-mers:  51%|█████▏    | 200/390 [01:46<01:47,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory] After encoding 200 files - Process: 12.24GB, Available: 11.06GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding [3, 4]-mers:  77%|███████▋  | 300/390 [02:39<00:56,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory] After encoding 300 files - Process: 12.24GB, Available: 11.06GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding [3, 4]-mers: 100%|██████████| 390/390 [03:28<00:00,  1.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[K-mer Encoding] Final feature matrix shape: (390, 162650)\n",
      "[Memory] After encoding complete - Process: 12.24GB, Available: 11.06GB\n",
      "[Prediction] Completed predictions for 390 examples.\n",
      "[Memory] After prediction - Process: 12.24GB, Available: 11.06GB\n",
      "Predictions written to `/home/ccdd/Documents/airr-ml/results/1122_3_4_mer_min_kmer_count_20/train_dataset_8_test_predictions.tsv`.\n",
      "Important sequences written to `/home/ccdd/Documents/airr-ml/results/1122_3_4_mer_min_kmer_count_20/train_dataset_8_important_sequences.tsv`.\n",
      "\n",
      "Dataset 8 completed successfully.\n",
      "[Memory] After Dataset 8 - Process: 8.47GB, Available: 14.81GB\n",
      "\n",
      "================================================================================\n",
      "Pipeline execution complete!\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Configuration\n",
    "train_datasets_dir = \"./Documents/airr-ml/data/train_datasets\"\n",
    "test_datasets_dir = \"./Documents/airr-ml/data/test_datasets\"\n",
    "results_dir = \"./Documents/airr-ml/results/1122_3_4_mer_min_kmer_count_20\"\n",
    "\n",
    "# K-mer configuration\n",
    "K_MERS = [3, 4]  # Combine 3-mers and 4-mers\n",
    "MIN_KMER_COUNT = 20  # Filter out rare k-mers (memory optimization)\n",
    "\n",
    "# Create output directory\n",
    "os.makedirs(results_dir, exist_ok=True)\n",
    "print(f\"Results will be saved to: {results_dir}\")\n",
    "\n",
    "# Get all dataset pairs\n",
    "train_test_dataset_pairs = get_dataset_pairs(train_datasets_dir, test_datasets_dir)\n",
    "\n",
    "print(f\"\\nFound {len(train_test_dataset_pairs)} total datasets\")\n",
    "print(\"Processing all datasets...\\n\")\n",
    "\n",
    "MemoryMonitor.log_memory(\"Before processing\")\n",
    "\n",
    "# Process all datasets\n",
    "for train_dir, test_dirs in train_test_dataset_pairs[7:8]:\n",
    "    dataset_num = os.path.basename(train_dir).replace('train_dataset_', '')\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"Processing Dataset {dataset_num}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    try:\n",
    "        main(\n",
    "            train_dir=train_dir, \n",
    "            test_dirs=test_dirs, \n",
    "            out_dir=results_dir,\n",
    "            n_jobs=4,\n",
    "            device=\"cpu\",  # GPU does not help much here\n",
    "            k_list=K_MERS,\n",
    "            min_kmer_count=MIN_KMER_COUNT,\n",
    "            save_model=True  # Save the trained model\n",
    "        )\n",
    "        print(f\"\\nDataset {dataset_num} completed successfully.\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\nError processing Dataset {dataset_num}: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "    \n",
    "    # Cleanup\n",
    "    gc.collect()\n",
    "    MemoryMonitor.log_memory(f\"After Dataset {dataset_num}\")\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"Pipeline execution complete!\")\n",
    "print(f\"{'='*80}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38415444",
   "metadata": {},
   "source": [
    "## Concatenate Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "48989b45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Concatenating output files...\n",
      "Concatenated output written to `/home/ccdd/Documents/airr-ml/results/1122_3_4_mer_min_kmer_count_20/submissions.csv`.\n",
      "Results concatenation complete!\n"
     ]
    }
   ],
   "source": [
    "# After successful test on dataset 7, concatenate results\n",
    "print(f\"\\nConcatenating output files...\")\n",
    "concatenate_output_files(results_dir)\n",
    "print(\"Results concatenation complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c67e9c",
   "metadata": {},
   "source": [
    "## Summary and Next Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dfebf865",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "╔════════════════════════════════════════════════════════════════════════════╗\n",
      "║              Combined K-mer Baseline Model - Summary                        ║\n",
      "╚════════════════════════════════════════════════════════════════════════════╝\n",
      "\n",
      "KEY FEATURES:\n",
      "✓ Combines 3-mers and 4-mers for richer biological signals\n",
      "✓ L1 regularization automatically selects useful k-mers\n",
      "✓ Memory-aware batch processing with garbage collection\n",
      "✓ Filters rare k-mers to reduce feature space\n",
      "✓ Continuous memory monitoring throughout pipeline\n",
      "\n",
      "MEMORY OPTIMIZATIONS:\n",
      "• Two-pass encoding: collect frequent k-mers first, then encode\n",
      "• K-mer filtering: keeps only k-mers with count >= 2\n",
      "• Batch processing: processes sequences in chunks\n",
      "• Explicit garbage collection: periodic memory cleanup\n",
      "• Top sequences: saving 50,000 sequences ranked by importance score\n",
      "\n",
      "RESULTS DIRECTORY:\n",
      "/home/ccdd/Documents/airr-ml/results/1122_3_4_mer_min_kmer_count_20\n",
      "\n",
      "IMPORTANT SEQUENCES OUTPUT:\n",
      "• Saves top 50,000 unique sequences ranked by importance score\n",
      "• Includes importance_score column showing ranking\n",
      "• Sequences ranked by model coefficient scores\n",
      "• Format: ID, dataset, label_positive_probability, junction_aa, v_call, j_call, importance_score\n",
      "\n",
      "NEXT STEPS:\n",
      "1. Verify all dataset results look reasonable\n",
      "2. Monitor memory usage from logs\n",
      "3. Check importance_score distribution across sequences\n",
      "4. Compare results with single k-mer baseline models\n",
      "5. Submit important_sequences for evaluation\n",
      "\n",
      "KEY METRICS TO MONITOR:\n",
      "• ROC-AUC cross-validation scores\n",
      "• Validation scores on held-out data\n",
      "• Memory usage growth\n",
      "• Number of features selected by L1 regularization\n",
      "• Importance score range and distribution\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\"\"\n",
    "╔════════════════════════════════════════════════════════════════════════════╗\n",
    "║              Combined K-mer Baseline Model - Summary                        ║\n",
    "╚════════════════════════════════════════════════════════════════════════════╝\n",
    "\n",
    "KEY FEATURES:\n",
    "✓ Combines 3-mers and 4-mers for richer biological signals\n",
    "✓ L1 regularization automatically selects useful k-mers\n",
    "✓ Memory-aware batch processing with garbage collection\n",
    "✓ Filters rare k-mers to reduce feature space\n",
    "✓ Continuous memory monitoring throughout pipeline\n",
    "\n",
    "MEMORY OPTIMIZATIONS:\n",
    "• Two-pass encoding: collect frequent k-mers first, then encode\n",
    "• K-mer filtering: keeps only k-mers with count >= 2\n",
    "• Batch processing: processes sequences in chunks\n",
    "• Explicit garbage collection: periodic memory cleanup\n",
    "• Top sequences: saving 50,000 sequences ranked by importance score\n",
    "\n",
    "RESULTS DIRECTORY:\n",
    "\"\"\" + results_dir + \"\"\"\n",
    "\n",
    "IMPORTANT SEQUENCES OUTPUT:\n",
    "• Saves top 50,000 unique sequences ranked by importance score\n",
    "• Includes importance_score column showing ranking\n",
    "• Sequences ranked by model coefficient scores\n",
    "• Format: ID, dataset, label_positive_probability, junction_aa, v_call, j_call, importance_score\n",
    "\n",
    "NEXT STEPS:\n",
    "1. Verify all dataset results look reasonable\n",
    "2. Monitor memory usage from logs\n",
    "3. Check importance_score distribution across sequences\n",
    "4. Compare results with single k-mer baseline models\n",
    "5. Submit important_sequences for evaluation\n",
    "\n",
    "KEY METRICS TO MONITOR:\n",
    "• ROC-AUC cross-validation scores\n",
    "• Validation scores on held-out data\n",
    "• Memory usage growth\n",
    "• Number of features selected by L1 regularization\n",
    "• Importance score range and distribution\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "443715be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create models directory\n",
    "# models_dir = \"/home/ccdd/Documents/airr-ml/models\"\n",
    "\n",
    "# # Save the model (for each dataset)\n",
    "# save_model(predictor, models_dir, dataset_name=\"dataset_1\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "airr-ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
